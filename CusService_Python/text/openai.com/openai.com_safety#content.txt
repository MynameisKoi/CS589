


Safety & responsibility













CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexGPT-4DALLÂ·E 3APIOverviewPricingDocsChatGPTOverviewTeamEnterprisePricingTry ChatGPTSafetyCompanyAboutBlogCareersResidencyCharterSecurityCustomer storiesSearch Navigation quick links Log inTry ChatGPTMenu Mobile Navigation CloseSite NavigationResearchOverviewIndexGPT-4DALLÂ·E 3APIOverviewPricingDocsChatGPTOverviewTeamEnterprisePricingTry ChatGPTSafetyCompanyAboutBlogCareersResidencyCharterSecurityCustomer stories Quick Links Log inTry ChatGPTSearch Submit Developing safe & responsible AIArtificial general intelligence has the potential to benefit nearly every aspect of our livesâso it must be developed and deployed responsibly.Play videoAI systems are becoming a part of everyday life. The key is to ensure that these machines are aligned with human intentions and values.Mira MuratiChief Technology Officer at OpenAIA focus on safetyAI technology comes with tremendous benefits, along with serious risk of misuse. Our Charter guides every aspect of our work to ensure that we prioritize the development of safe and beneficial AI.null linksRead our CharterRead our approach to alignment researchOpenAI safety teamsOur teams span a wide spectrum of technical efforts tackling AI safety challenges at OpenAI.  The Safety Systems team stays closest to the deployment risk while our Superalignment team focuses on aligning superintelligence and our Preparedness team focuses on safety assessments for frontier models.null linksRead about our Safety Systems teamRead about our Preparedness teamRead about our Superalignment teamSharing our expertiseWe collaborate with industry leaders and policymakers to ensure that AI systems are developed in a trustworthy manner.Forecasting potential misuses of language models for disinformation campaigns and how to reduce riskJan 11, 2023January 11, 2023Best practices for deploying language modelsJun 2, 2022June 2, 2022Lessons learned on language model safety and misuseMar 3, 2022March 3, 2022Why responsible AI development needs cooperation on safetyJul 10, 2019July 10, 2019This technology will profoundly transform how we live. There is still time to guide its trajectory, limit abuse, and secure the most broadly beneficial outcomes.Anna MakanjuHead of Public Policy at OpenAISafety in practiceWe develop risk mitigation tools, best practices for responsible use, and monitor our platforms for misuse.View product safety standardsNew AI classifier for indicating AI-written textJan 31, 2023January 31, 2023New and improved content moderation toolingAug 10, 2022August 10, 2022DALLÂ·E 2 pre-training mitigationsJun 28, 2022June 28, 2022ResearchOverviewIndexGPT-4DALLÂ·E 3APIOverviewPricingDocsChatGPTOverviewTeamEnterprisePricingTry ChatGPTCompanyAboutBlogCareersCharterSecurityCustomer storiesSafetyOpenAI Â© 2015âââ2024Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
