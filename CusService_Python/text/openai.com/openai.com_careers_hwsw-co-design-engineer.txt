


HW/SW Co-design Engineer









CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexGPT-4DALLÂ·E 3APIOverviewPricingDocsChatGPTOverviewTeamEnterprisePricingTry ChatGPTSafetyCompanyAboutBlogCareersResidencyCharterSecurityCustomer storiesSearch Navigation quick links Log inTry ChatGPTMenu Mobile Navigation CloseSite NavigationResearchOverviewIndexGPT-4DALLÂ·E 3APIOverviewPricingDocsChatGPTOverviewTeamEnterprisePricingTry ChatGPTSafetyCompanyAboutBlogCareersResidencyCharterSecurityCustomer stories Quick Links Log inTry ChatGPTSearch Submit CareersHW/SW Co-design EngineerSan Francisco, California, United States â Research, Engineering, ProductApply nowAbout the TeamOur mission at OpenAI is to discover and enact the path to safe, beneficial AGI. To do this, we believe that many technical breakthroughs are needed in generative modeling, reinforcement learning, large scale optimization, active learning, among other topics.The Research Platform team builds robust and scalable software to support our research efforts. It also offers core development services for mission critical goals and applications. In the Kernels team, we write Kernels for GPUs, we build a compiler to support important AI accelerators and we help with HW/SW co-design of future AI accelerators.Â About the RoleAs a Research Engineer, you will help build AI systems that can perform previously impossible tasks or achieve outstanding levels of performance. This requires good engineering (for example designing, implementing, and optimizing state-of-the-art AI models), writing bug-free machine learning code (surprisingly difficult!), and building the science behind the algorithms employed. In all the projects this role pursues, the ultimate goal is to push the field forward.As a Research Engineer for HW/SW co-design, you will co-design future hardware from different vendors for programmability and performance. You will work with our kernel, compiler and ML developers to understand their needs related to ML techniques, algorithms, numerical approximations, programming expressivity and compiler optimizations. You will evangelize these constraints with various vendors to develop future hardware architectures amenable for efficient training and inference. If you are excited about maximizing HBM bandwidth, optimizing for low arithmetic intensity, expressive SIMD ISA, low-precision formats, optimizing for memory hierarchies, simulating workloads at various resolutions of the hardware and evangelizing these ideas with hardware engineers, this is the perfect opportunity!This role is based in San Francisco, CA. We use a hybrid work model of 3 days in the office per week and offer relocation assistance to new employees.In this role, you will:Work with hardware vendors to help co-design their future hardware for programmability and performanceAssist hardware vendors in developing optimal kernels and add support for it in our compilerDevelop performance estimates for critical kernels for different hardware configurationsÂ Work with ML engineers, kernel engineers and compiler developers to understand their vision and needs from high performance acceleratorsManage communication and coordination with internal and external engagementsYou might thrive in this role if youHave a deep understanding of GPU and/or other AI acceleratorsHave good experience with CUDA or a related accelerator programming languageHave experience driving ML accuracy with low precision formatsAble to actively collaborate with ML engineers, kernel writers and compiler developersHave 3+ years of relevant industry experienceGet a great deal of satisfaction with aligning future hardware with a well established HPC infrastructureThese attributes are nice to havePhD in Computer Science and Engineering with a specialization in Computer Architecture, Parallel Computing. Compilers or other SystemsAre a strong coder with excellent skills in C/C++ and PythonExperience working with hardware developersExperience building compilersGood understanding of LLMs and challenges related to their training and inferenceÂ Benefits and PerksMedical, dental, and vision insurance for you and your familyMental health and wellness support401(k) plan with 4% matchingUnlimited time off and 18+ company holidays per yearPaid parental leave (20 weeks) and family-planning supportAnnual learning & development stipend ($1,500 per year)About OpenAIOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.Â We are an equal opportunity employer and do not discriminate on the basis of race, religion, national origin, gender, sexual orientation, age, veteran status, disability or any other legally protected status.Â For US Based Candidates: Pursuant to the San Francisco Fair Chance Ordinance, we will consider qualified applicants with arrest and conviction records.We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via thisÂ link.OpenAI Global Applicant Privacy PolicyAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.Apply nowResearchOverviewIndexGPT-4DALLÂ·E 3APIOverviewPricingDocsChatGPTOverviewTeamEnterprisePricingTry ChatGPTCompanyAboutBlogCareersCharterSecurityCustomer storiesSafetyOpenAI Â© 2015âââ2024Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
