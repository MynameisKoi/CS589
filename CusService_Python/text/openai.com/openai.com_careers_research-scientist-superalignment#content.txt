


Research Scientist, Superalignment









CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexGPT-4DALLÂ·E 3APIOverviewPricingDocsChatGPTOverviewTeamEnterprisePricingTry ChatGPTSafetyCompanyAboutBlogCareersResidencyCharterSecurityCustomer storiesSearch Navigation quick links Log inTry ChatGPTMenu Mobile Navigation CloseSite NavigationResearchOverviewIndexGPT-4DALLÂ·E 3APIOverviewPricingDocsChatGPTOverviewTeamEnterprisePricingTry ChatGPTSafetyCompanyAboutBlogCareersResidencyCharterSecurityCustomer stories Quick Links Log inTry ChatGPTSearch Submit CareersResearch Scientist, SuperalignmentSan Francisco, California, United States â AlignmentApply nowAbout the TeamOpenAIâs Superalignment Team is working on technical approaches to ensure that superintelligenceâan AI system vastly smarter than humansâfollows human intent.Â Through scientific experimentation, we explore the scalability of alignment techniques and identify potential breaking points. Our approach to alignment research includes a range of different projects; some of these will help us improve the alignment of our models and others will allow us to validate how aligned our models actually are:Scalable oversight: How can we best leverage AI systems to assist evaluation of other AI systems on difficult tasks?Generalization: Can we understand and control how our models generalize from easy tasks that humans can supervise to hard tasks that humans cannot?Automated interpretability: Can we use AI to explain how LLMs work internally?Robustness: How can we train our models to be aligned in worst-case situations?Adversarial testing: If we deliberately train deceptively aligned models as testbeds,Â  can our oversight techniques, interpretability tools, and evaluations detect this misalignment?We want to figure out how to spend vast amounts of compute to solve this problem, in particular by automating alignment research itself. About the RoleAs a Research Scientist here, you will develop innovative machine learning techniques and advance the research agenda of the Superalignment team, while also collaborating with peers across the organization. We are looking for people who want to discover simple, generalizable ideas that work well even at large scale, and form part of a broader research vision that unifies the entire company.We are seeking Research Scientists to help design and implement experiments for alignment research. Responsibilities may include:Designing experiments to measure the effectiveness of scalable oversight techniques such as AI-assisted feedback and DebateStudying generalization to see when AI systems trained on easy problems can solve hard problemsManaging large datasets from interpretability experiments and creating visualizations to explore interpretability dataDeveloping experiments to test how well chain of thought reasoning reflects model cognitionInvestigating situations when training against a reward signal causes model outputs to deteriorateExploring methods to understand and predict model behaviors, such as finding inputs causing anomalous circuits or catastrophic outputsDesigning novel approaches for using LLMs in alignment researchYou might thrive in this role if you:Are excited about OpenAIâs mission of building safe, universally beneficial AGI and are aligned with OpenAIâs charter.Have a track record of coming up with new ideas or improving upon existing ideas in machine learning, demonstrated by accomplishments such as first author publications or projectsPossess the ability to own and pursue a research agenda, including choosing impactful research problems and autonomously carrying out long-running projectsPossess a strong curiosity about aligning and understanding ML models, and are motivated to use your career to address this challengeEnjoy fast-paced, collaborative, and cutting-edge research environmentsHave experience implementing ML algorithms (e.g., PyTorch)Can develop data visualization or data collection interfaces (e.g., JavaScript, Python)Want to ensure that powerful AI systems stay under human controlCompensation, Benefits and PerksTotal compensation also includes generous equity and benefits.Medical, dental, and vision insurance for you and your familyMental health and wellness support401(k) plan with 4% matchingUnlimited time off and 18+ company holidays per yearPaid parental leave (20 weeks) and family-planning supportAnnual learning & development stipend ($1,500 per year)Annual Salary Range$245,000â$440,000 USDAbout OpenAIOpenAI is an AI research and deployment company dedicated to ensuring that general-purpose artificial intelligence benefits all of humanity. We push the boundaries of the capabilities of AI systems and seek to safely deploy them to the world through our products. AI is an extremely powerful tool that must be created with safety and human needs at its core, and to achieve our mission, we must encompass and value the many different perspectives, voices, and experiences that form the full spectrum of humanity.Â We are an equal opportunity employer and do not discriminate on the basis of race, religion, national origin, gender, sexual orientation, age, veteran status, disability or any other legally protected status.Â For US Based Candidates: Pursuant to the San Francisco Fair Chance Ordinance, we will consider qualified applicants with arrest and conviction records.We are committed to providing reasonable accommodations to applicants with disabilities, and requests can be made via thisÂ link.OpenAI Global Applicant Privacy PolicyAt OpenAI, we believe artificial intelligence has the potential to help people solve immense global challenges, and we want the upside of AI to be widely shared. Join us in shaping the future of technology.Apply nowResearchOverviewIndexGPT-4DALLÂ·E 3APIOverviewPricingDocsChatGPTOverviewTeamEnterprisePricingTry ChatGPTCompanyAboutBlogCareersCharterSecurityCustomer storiesSafetyOpenAI Â© 2015âââ2024Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
