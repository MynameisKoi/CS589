


ChatGPT can now see, hear, and speak













CloseSearch Submit Skip to main contentSite NavigationResearchOverviewIndexGPT-4DALLÂ·E 3APIOverviewPricingDocsChatGPTOverviewTeamEnterprisePricingTry ChatGPTSafetyCompanyAboutBlogCareersResidencyCharterSecurityCustomer storiesSearch Navigation quick links Log inTry ChatGPTMenu Mobile Navigation CloseSite NavigationResearchOverviewIndexGPT-4DALLÂ·E 3APIOverviewPricingDocsChatGPTOverviewTeamEnterprisePricingTry ChatGPTSafetyCompanyAboutBlogCareersResidencyCharterSecurityCustomer stories Quick Links Log inTry ChatGPTSearch Submit BlogChatGPT can now see, hear, and speakWe are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what youâre talking about.September 25, 2023AuthorsOpenAI Product,Â AnnouncementsWe are beginning to roll out new voice and image capabilities in ChatGPT. They offer a new, more intuitive type of interface by allowing you to have a voice conversation or show ChatGPT what youâre talking about.Voice and image give you more ways to use ChatGPT in your life. Snap a picture of a landmark while traveling and have a live conversation about whatâs interesting about it. When youâre home, snap pictures of your fridge and pantry to figure out whatâs for dinner (and ask follow up questions for a step by step recipe). After dinner, help your child with a math problem by taking a photo, circling the problem set, and having it share hints with both of you.Weâre rolling out voice and images in ChatGPT to Plus and Enterprise users over the next two weeks. Voice is coming on iOS and Android (opt-in in your settings) and images will be available on all platforms.Speak with ChatGPT and have it talk backYou can now use voice to engage in a back-and-forth conversation with your assistant. Speak with it on the go, request a bedtime story for your family, or settle a dinner table debate.Speak with ChatGPT and have it talk back1:42Use voice to engage in a back-and-forth conversation with your assistant.To get started with voice, head to Settings â New Features on the mobile app and opt into voice conversations. Then, tap the headphone button located in the top-right corner of the home screen and choose your preferred voice out of five different voices.The new voice capability is powered by a new text-to-speech model, capable of generating human-like audio from just text and a few seconds of sample speech. We collaborated with professional voice actors to create each of the voices. We also use Whisper, our open-source speech recognition system, to transcribe your spoken words into text.Listen to voice samplesSelect textStoryRecipeSpeechPoemExplanationOnce in a tranquil woodland, there was a fluffy mama cat named Lila. One sunny day, she cuddled with her playful kitten, Milo, under the shade of an old oak tree.âMilo,â Lila began, her voice soft and gentle, âyouâre going to have a new playmate soon.âMiloâs ears perked up, curious. âA new playmate?âLila purred, âYes, a baby sister.âMiloâs eyes widened with excitement. âA sister? Will she chase tails like I do?âLila chuckled. âOh, sheâll have her own quirks. Youâll teach her, wonât you?âMilo nodded eagerly, already dreaming of the adventures theyâd share.Select voiceJuniperSkyCoveEmberBreezeChat about imagesYou can now show ChatGPT one or more images. Troubleshoot why your grill wonât start, explore the contents of your fridge to plan a meal, or analyze a complex graph for work-related data. To focus on a specific part of the image, you can use the drawing tool in our mobile app.Chat about images1:29Show ChatGPT one or more images.To get started, tap the photo button to capture or choose an image. If youâre on iOS or Android, tap the plus button first. You can also discuss multiple images or use our drawing tool to guide your assistant.Image understanding is powered by multimodal GPT-3.5 and GPT-4. These models apply their language reasoning skills to a wide range of images, such as photographs, screenshots, and documents containing both text and images.We are deploying image and voice capabilities graduallyOpenAIâs goal is to build AGI that is safe and beneficial. We believe in making our tools available gradually, which allows us to make improvements and refine risk mitigations over time while also preparing everyone for more powerful systems in the future. This strategy becomes even more important with advanced models involving voice and vision.VoiceThe new voice technologyâcapable of crafting realistic synthetic voices from just a few seconds of real speechâopens doors to many creative and accessibility-focused applications. However, these capabilities also present new risks, such as the potential for malicious actors to impersonate public figures or commit fraud.This is why we are using this technology to power a specific use caseâvoice chat. Voice chat was created with voice actors we have directly worked with. Weâre also collaborating in a similar way with others. For example, Spotify is using the power of this technology for the pilot of their Voice Translation feature, which helps podcasters expand the reach of their storytelling by translating podcasts into additional languages in the podcastersâ own voices.Image inputVision-based models also present new challenges, ranging from hallucinations about people to relying on the modelâs interpretation of images in high-stakes domains. Prior to broader deployment, we tested the model with red teamers for risk in domains such as extremism and scientific proficiency, and a diverse set of alpha testers. Our research enabled us to align on a few key details for responsible usage.Making vision both useful and safeLike other ChatGPT features, vision is about assisting you with your daily life. It does that best when it can see what you see.Â This approach has been informed directly by our work with Be My Eyes, a free mobile app for blind and low-vision people, to understand uses and limitations. Users have told us they find it valuable to have general conversations about images that happen to contain people in the background, like if someone appears on TV while youâre trying to figure out your remote control settings.Weâve also taken technical measures to significantly limit ChatGPTâs ability to analyze and make direct statements about people since ChatGPT is not always accurate and these systems should respect individualsâ privacy.Real world usage and feedback will help us make these safeguards even better while keeping the tool useful.Transparency about model limitationsUsers might depend on ChatGPT for specialized topics, for example in fields like research. We are transparent about the model's limitations and discourage higher risk use cases without proper verification. Furthermore, the model is proficient at transcribing English text but performs poorly with some other languages, especially those with non-roman script. We advise our non-English users against using ChatGPT for this purpose.You can read more about our approach to safety and our work with Be My Eyes in the system card for image input.We will be expanding accessPlus and Enterprise users will get to experience voice and images in the next two weeks. Weâre excited to roll out these capabilities to other groups of users, including developers, soon after.AuthorsOpenAI View all articlesAcknowledgmentsVoice mode core researchAlec Radford, Tao Xu, Jong Wook KimVision deployment core researchRaul Puri, Jamie Kiros, Hyeonwoo Noh, Long Ouyang, Sandhini AgarwalView GPT-4V(ision) technical work and authorsResearchOverviewIndexGPT-4DALLÂ·E 3APIOverviewPricingDocsChatGPTOverviewTeamEnterprisePricingTry ChatGPTCompanyAboutBlogCareersCharterSecurityCustomer storiesSafetyOpenAI Â© 2015âââ2024Terms & policiesPrivacy policyBrand guidelinesSocialTwitterYouTubeGitHubSoundCloudLinkedInBack to top
